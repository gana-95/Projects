{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>MN_228S8</th>\n",
       "      <th>MN_229A</th>\n",
       "      <th>MN_230A</th>\n",
       "      <th>MN_233A</th>\n",
       "      <th>MN_237B1</th>\n",
       "      <th>MN_249A1</th>\n",
       "      <th>MN_249A3</th>\n",
       "      <th>I_RELIGBEL</th>\n",
       "      <th>I_NORM1</th>\n",
       "      <th>I_VOICE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_228S8  MN_229A  MN_230A  \\\n",
       "0  12   1   1   1  -2   1   1    2    1    1  ...         3       -3       -3   \n",
       "1  12   1   2   3   4   2   2    2    2    2  ...         3       -3       -3   \n",
       "2  12   1   3   2   4   2   1    2    2    2  ...         4        1        1   \n",
       "3  12   1   1   3   4   3   1    2    1    2  ...         2        2        1   \n",
       "4  12   1   1   1   2   1   1    1    3    2  ...         2        2        1   \n",
       "\n",
       "   MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  I_VOICE1  \n",
       "0       -3        -3         1         1         0.0      1.0      0.00  \n",
       "1       -3        -3         2        -1         0.0      1.0      0.66  \n",
       "2        2        -3         1         1         0.0      1.0      0.33  \n",
       "3        2        -3         1         2         0.0      1.0      0.00  \n",
       "4        2        -3         1         2         0.0      1.0      0.66  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs = pd.read_csv('wvs.csv.bz2', sep = '\\t')\n",
    "wvs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90350, 328)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 328 variables and ~90k observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90350.000000\n",
       "mean         2.946386\n",
       "std          2.964040\n",
       "min         -5.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          5.000000\n",
       "max         10.000000\n",
       "Name: V204, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs.V204.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18eebf28400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(wvs.V204, bins = 15, kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The abortion column has 85742 non-missing responses\n"
     ]
    }
   ],
   "source": [
    "print(\"The abortion column has\", wvs[wvs.V204 > 0].count().V204, \"non-missing responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85742, 328)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs1 = wvs[wvs.V204 > 0].reset_index()# Removing the the obs that has negative values in V204\n",
    "wvs1 = wvs1.drop('index', axis = 1)\n",
    "wvs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 328)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs1 = wvs1.dropna() # dropping the observations that has missing values\n",
    "wvs1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 329)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the binary variable abortion\n",
    "wvs1['abortion'] = (wvs1.V204 > 3).astype(int)\n",
    "wvs1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = wvs1.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abortion    1.000000\n",
       "V204        0.881048\n",
       "V205        0.548653\n",
       "V203        0.485419\n",
       "V206        0.446394\n",
       "V207        0.418271\n",
       "V9          0.314117\n",
       "V203A       0.291576\n",
       "V146        0.272220\n",
       "V210        0.257035\n",
       "Name: abortion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['abortion'].sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V217   -0.117946\n",
       "V106   -0.121063\n",
       "V107   -0.134199\n",
       "V222   -0.140166\n",
       "V132   -0.140972\n",
       "V138   -0.142894\n",
       "V255   -0.149844\n",
       "V223   -0.165924\n",
       "V252   -0.191483\n",
       "V152   -0.315280\n",
       "Name: abortion, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['abortion'].sort_values(ascending = False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 327)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the highly correlated variables to exclude the bias\n",
    "# Considering the variables that has correlation > |0.5|\n",
    "wvs1 = wvs1.drop(['V204', 'V205'], axis = 1) #V204 - abortion, V205 - divorce\n",
    "wvs1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs1 = wvs1.rename(columns = {'V2': 'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs1 = pd.get_dummies(wvs1, columns = ['country']) # Creating the dummy variables for the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>...</th>\n",
       "      <th>country_752</th>\n",
       "      <th>country_764</th>\n",
       "      <th>country_780</th>\n",
       "      <th>country_788</th>\n",
       "      <th>country_792</th>\n",
       "      <th>country_804</th>\n",
       "      <th>country_840</th>\n",
       "      <th>country_858</th>\n",
       "      <th>country_860</th>\n",
       "      <th>country_887</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V4  V5  V6  V7  V8  V9  V10  V11  V12  V13  ...  country_752  country_764  \\\n",
       "0   1   1   1  -2   1   1    2    1    1    1  ...            0            0   \n",
       "1   1   2   3   4   2   2    2    2    2    1  ...            0            0   \n",
       "2   1   3   2   4   2   1    2    2    2    2  ...            0            0   \n",
       "3   1   1   3   4   3   1    2    1    2    2  ...            0            0   \n",
       "4   1   1   1   2   1   1    1    3    2    1  ...            0            0   \n",
       "\n",
       "   country_780  country_788  country_792  country_804  country_840  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   country_858  country_860  country_887  \n",
       "0            0            0            0  \n",
       "1            0            0            0  \n",
       "2            0            0            0  \n",
       "3            0            0            0  \n",
       "4            0            0            0  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 383)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs1 = wvs1.drop('country_887', axis = 1)\n",
    "wvs1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement k-Cross Fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_val(k, clf, X, y):\n",
    "    # Shuffle Indices\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    X = X[shuffled_indices]\n",
    "    y = y[shuffled_indices]\n",
    "    \n",
    "    # Splitting predictors and predictands into k folds\n",
    "    X_split = np.array_split(X, k)\n",
    "    y_split = np.array_split(y, k)\n",
    "    \n",
    "    # Intializing the classification scores\n",
    "    f1_score_sum = 0\n",
    "    accuracy_sum = 0\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        X_train = X_split.copy() # Creating a copy of the predictors\n",
    "        X_valid = X_split[i]     # Validation predictors\n",
    "        y_train = y_split.copy() # Copy of the target\n",
    "        y_valid = y_split[i]     # Validation target\n",
    "        del X_train[i]           # Deleting the validation predictors from the training\n",
    "        del y_train[i]           # Deleting the validation target from the training\n",
    "        \n",
    "        # Concatenate the folds into single array\n",
    "        X_train = np.concatenate(X_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        \n",
    "        # Performing the model and getting classification scores after each iteration\n",
    "        f1, acc, prec, rec = perform(i, clf, X_train, y_train, X_valid, y_valid)\n",
    "        \n",
    "        # Summing the classification scores after each iteration\n",
    "        f1_score_sum = f1_score_sum + f1\n",
    "        accuracy_sum = accuracy_sum + acc\n",
    "        precision_sum = precision_sum + prec\n",
    "        recall_sum = recall_sum + rec\n",
    "    \n",
    "    print(\"Average f1-score:\", round((f1_score_sum/k), 2))\n",
    "    print(\"Average accuracy:\", round((accuracy_sum/k), 2))\n",
    "    print(\"Average precision:\", round((precision_sum/k), 2))\n",
    "    print(\"Average recall:\", round((recall_sum/k), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(a, clf, X_train, y_train, X_valid, y_valid):\n",
    "    from sklearn import metrics # importing the metrics library to calculate classification scores\n",
    "    clf.fit(X_train, y_train) # Fitting the model with the training data\n",
    "    y_pred = clf.predict(X_valid) # Predicting the target with validation data\n",
    "    \n",
    "    # Calculating the scores\n",
    "    f1_score = metrics.f1_score(y_valid, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_valid, y_pred)\n",
    "    precision = metrics.precision_score(y_valid, y_pred)\n",
    "    recall = metrics.recall_score(y_valid, y_pred)\n",
    "    \n",
    "    print(str(a + 1), \". F1-score:\", round(f1_score, 2), \"\\tAccuracy:\", round(accuracy, 2))\n",
    "    print(\"\\tPrecision:\", round(precision, 2), \"\\tRecall:\", round(recall, 2))\n",
    "    return f1_score, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.69 \tAccuracy: 0.78\n",
      "\tPrecision: 0.71 \tRecall: 0.66\n",
      "2 . F1-score: 0.67 \tAccuracy: 0.77\n",
      "\tPrecision: 0.73 \tRecall: 0.62\n",
      "3 . F1-score: 0.68 \tAccuracy: 0.78\n",
      "\tPrecision: 0.75 \tRecall: 0.61\n",
      "4 . F1-score: 0.65 \tAccuracy: 0.76\n",
      "\tPrecision: 0.69 \tRecall: 0.61\n",
      "5 . F1-score: 0.66 \tAccuracy: 0.77\n",
      "\tPrecision: 0.72 \tRecall: 0.61\n",
      "Average f1-score: 0.67\n",
      "Average accuracy: 0.77\n",
      "Average precision: 0.72\n",
      "Average recall: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Extracting random samples of 10k observations from the data \n",
    "wvs_work = wvs1.sample(n = 10000, random_state = 42).reset_index()\n",
    "wvs_work = wvs_work.drop('index', axis = 1)\n",
    "\n",
    "X = wvs_work.drop('abortion', axis = 1).to_numpy() # Predictors\n",
    "y = wvs_work['abortion'] # Target\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 5-fold CV with 5 neighbors\n",
    "kfold_cross_val(5, knn, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.69 \tAccuracy: 0.78\n",
      "\tPrecision: 0.73 \tRecall: 0.65\n",
      "2 . F1-score: 0.67 \tAccuracy: 0.78\n",
      "\tPrecision: 0.74 \tRecall: 0.61\n",
      "3 . F1-score: 0.68 \tAccuracy: 0.78\n",
      "\tPrecision: 0.77 \tRecall: 0.61\n",
      "4 . F1-score: 0.65 \tAccuracy: 0.77\n",
      "\tPrecision: 0.71 \tRecall: 0.6\n",
      "5 . F1-score: 0.68 \tAccuracy: 0.78\n",
      "\tPrecision: 0.75 \tRecall: 0.61\n",
      "Average f1-score: 0.67\n",
      "Average accuracy: 0.78\n",
      "Average precision: 0.74\n",
      "Average recall: 0.62\n"
     ]
    }
   ],
   "source": [
    "# 5-fold CV with 9 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "kfold_cross_val(5, knn, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the k-Nearest Neighbors algorithm with 5 neighbors, the average f1-score is 0.67, the accuracy is 0.77, precision is 0.72 and recall is 0.63. From the classification scores, what we can see is that the model is able to predict correctly whether someone is supporting the abortion or not 77% of the time. With the precision score we can see that the model predicts correctly whether someone is supporting the abortion 72% of the time and wrongly predicted it 28% of the time. Similarly for the recall the model predicts the people who support abortion 63% of the time.\n",
    "\n",
    "With 9 neighbors, we could see there is a slight increase in the accuracy and precision but the model doesn't deviate much from the result of 5 negihbors classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.76 \tAccuracy: 0.83\n",
      "\tPrecision: 0.78 \tRecall: 0.74\n",
      "2 . F1-score: 0.75 \tAccuracy: 0.82\n",
      "\tPrecision: 0.77 \tRecall: 0.72\n",
      "3 . F1-score: 0.75 \tAccuracy: 0.82\n",
      "\tPrecision: 0.79 \tRecall: 0.71\n",
      "4 . F1-score: 0.73 \tAccuracy: 0.82\n",
      "\tPrecision: 0.8 \tRecall: 0.68\n",
      "5 . F1-score: 0.77 \tAccuracy: 0.82\n",
      "\tPrecision: 0.8 \tRecall: 0.74\n",
      "6 . F1-score: 0.78 \tAccuracy: 0.85\n",
      "\tPrecision: 0.81 \tRecall: 0.76\n",
      "7 . F1-score: 0.73 \tAccuracy: 0.81\n",
      "\tPrecision: 0.77 \tRecall: 0.69\n",
      "8 . F1-score: 0.74 \tAccuracy: 0.83\n",
      "\tPrecision: 0.79 \tRecall: 0.69\n",
      "9 . F1-score: 0.72 \tAccuracy: 0.81\n",
      "\tPrecision: 0.77 \tRecall: 0.68\n",
      "10 . F1-score: 0.76 \tAccuracy: 0.83\n",
      "\tPrecision: 0.79 \tRecall: 0.72\n",
      "Average f1-score: 0.75\n",
      "Average accuracy: 0.82\n",
      "Average precision: 0.79\n",
      "Average recall: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "\n",
    "kfold_cross_val(10, logReg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that the logistic regression model performs better than the knn model in terms of the classification scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "wvs_work1 = wvs1.sample(n = 1000, random_state = 42).reset_index()\n",
    "wvs_work1 = wvs_work1.drop('index', axis = 1)\n",
    "\n",
    "X1 = wvs_work1.drop('abortion', axis = 1).to_numpy()\n",
    "y1 = wvs_work1['abortion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abortion\n",
       "0    0.638\n",
       "1    0.362\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_work1.groupby('abortion').size().div(len(wvs_work1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.6 \tAccuracy: 0.75\n",
      "\tPrecision: 0.58 \tRecall: 0.63\n",
      "2 . F1-score: 0.57 \tAccuracy: 0.67\n",
      "\tPrecision: 0.56 \tRecall: 0.58\n",
      "3 . F1-score: 0.63 \tAccuracy: 0.75\n",
      "\tPrecision: 0.62 \tRecall: 0.64\n",
      "4 . F1-score: 0.62 \tAccuracy: 0.72\n",
      "\tPrecision: 0.64 \tRecall: 0.61\n",
      "5 . F1-score: 0.61 \tAccuracy: 0.7\n",
      "\tPrecision: 0.62 \tRecall: 0.59\n",
      "6 . F1-score: 0.71 \tAccuracy: 0.77\n",
      "\tPrecision: 0.7 \tRecall: 0.72\n",
      "7 . F1-score: 0.72 \tAccuracy: 0.78\n",
      "\tPrecision: 0.74 \tRecall: 0.7\n",
      "8 . F1-score: 0.63 \tAccuracy: 0.72\n",
      "\tPrecision: 0.62 \tRecall: 0.65\n",
      "9 . F1-score: 0.69 \tAccuracy: 0.77\n",
      "\tPrecision: 0.59 \tRecall: 0.84\n",
      "10 . F1-score: 0.68 \tAccuracy: 0.76\n",
      "\tPrecision: 0.68 \tRecall: 0.68\n",
      "Average f1-score: 0.65\n",
      "Average accuracy: 0.74\n",
      "Average precision: 0.63\n",
      "Average recall: 0.66\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = 'linear')\n",
    "\n",
    "kfold_cross_val(10, svc, X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.69 \tAccuracy: 0.83\n",
      "\tPrecision: 0.76 \tRecall: 0.63\n",
      "2 . F1-score: 0.62 \tAccuracy: 0.74\n",
      "\tPrecision: 0.7 \tRecall: 0.55\n",
      "3 . F1-score: 0.58 \tAccuracy: 0.75\n",
      "\tPrecision: 0.65 \tRecall: 0.52\n",
      "4 . F1-score: 0.72 \tAccuracy: 0.81\n",
      "\tPrecision: 0.83 \tRecall: 0.63\n",
      "5 . F1-score: 0.71 \tAccuracy: 0.8\n",
      "\tPrecision: 0.83 \tRecall: 0.62\n",
      "6 . F1-score: 0.79 \tAccuracy: 0.85\n",
      "\tPrecision: 0.85 \tRecall: 0.74\n",
      "7 . F1-score: 0.78 \tAccuracy: 0.83\n",
      "\tPrecision: 0.79 \tRecall: 0.78\n",
      "8 . F1-score: 0.7 \tAccuracy: 0.79\n",
      "\tPrecision: 0.75 \tRecall: 0.65\n",
      "9 . F1-score: 0.73 \tAccuracy: 0.84\n",
      "\tPrecision: 0.76 \tRecall: 0.71\n",
      "10 . F1-score: 0.71 \tAccuracy: 0.8\n",
      "\tPrecision: 0.76 \tRecall: 0.68\n",
      "Average f1-score: 0.7\n",
      "Average accuracy: 0.8\n",
      "Average precision: 0.77\n",
      "Average recall: 0.65\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = 'rbf', gamma = 0.001, C = 100)\n",
    "kfold_cross_val(10, svc, X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.73 \tAccuracy: 0.85\n",
      "\tPrecision: 0.8 \tRecall: 0.67\n",
      "2 . F1-score: 0.62 \tAccuracy: 0.76\n",
      "\tPrecision: 0.77 \tRecall: 0.53\n",
      "3 . F1-score: 0.69 \tAccuracy: 0.82\n",
      "\tPrecision: 0.8 \tRecall: 0.61\n",
      "4 . F1-score: 0.72 \tAccuracy: 0.82\n",
      "\tPrecision: 0.88 \tRecall: 0.61\n",
      "5 . F1-score: 0.67 \tAccuracy: 0.78\n",
      "\tPrecision: 0.81 \tRecall: 0.56\n",
      "6 . F1-score: 0.7 \tAccuracy: 0.81\n",
      "\tPrecision: 0.92 \tRecall: 0.56\n",
      "7 . F1-score: 0.79 \tAccuracy: 0.85\n",
      "\tPrecision: 0.9 \tRecall: 0.7\n",
      "8 . F1-score: 0.7 \tAccuracy: 0.81\n",
      "\tPrecision: 0.85 \tRecall: 0.59\n",
      "9 . F1-score: 0.68 \tAccuracy: 0.83\n",
      "\tPrecision: 0.82 \tRecall: 0.58\n",
      "10 . F1-score: 0.63 \tAccuracy: 0.77\n",
      "\tPrecision: 0.77 \tRecall: 0.54\n",
      "Average f1-score: 0.69\n",
      "Average accuracy: 0.81\n",
      "Average precision: 0.83\n",
      "Average recall: 0.59\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = 'rbf', gamma = 0.0001)\n",
    "kfold_cross_val(10, svc, X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.69 \tAccuracy: 0.84\n",
      "\tPrecision: 0.82 \tRecall: 0.6\n",
      "2 . F1-score: 0.55 \tAccuracy: 0.74\n",
      "\tPrecision: 0.8 \tRecall: 0.42\n",
      "3 . F1-score: 0.63 \tAccuracy: 0.81\n",
      "\tPrecision: 0.89 \tRecall: 0.48\n",
      "4 . F1-score: 0.66 \tAccuracy: 0.8\n",
      "\tPrecision: 0.95 \tRecall: 0.5\n",
      "5 . F1-score: 0.65 \tAccuracy: 0.78\n",
      "\tPrecision: 0.87 \tRecall: 0.51\n",
      "6 . F1-score: 0.5 \tAccuracy: 0.72\n",
      "\tPrecision: 0.82 \tRecall: 0.36\n",
      "7 . F1-score: 0.74 \tAccuracy: 0.83\n",
      "\tPrecision: 0.96 \tRecall: 0.6\n",
      "8 . F1-score: 0.66 \tAccuracy: 0.8\n",
      "\tPrecision: 0.9 \tRecall: 0.51\n",
      "9 . F1-score: 0.61 \tAccuracy: 0.81\n",
      "\tPrecision: 0.83 \tRecall: 0.48\n",
      "10 . F1-score: 0.58 \tAccuracy: 0.75\n",
      "\tPrecision: 0.77 \tRecall: 0.46\n",
      "Average f1-score: 0.63\n",
      "Average accuracy: 0.79\n",
      "Average precision: 0.86\n",
      "Average recall: 0.49\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel = 'sigmoid', gamma = 0.0001)\n",
    "kfold_cross_val(10, svc, X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM sigmoid and rbf kernel models have a very good precision score but a poor recall score mainly because of the class imbalance in the dataset. There is almost 64% of people saying no to abortion and 36% saying yes. Since we have a very less positives in the sample, the models are able to predict very less false positives. But among the actual positives, why I think the models are not able to perform well is because the sample has large samples for negatives and there are high chances that the models predict the positives as negatives than the other way around. Thus, the difference between the precision and recall is mainly due to the class imbalance and we could see that in the other models too but it is too evident in the SVM models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the three models, I would pick the Logistic Regression model over the knn and SVM models. Logistic Regression model perform really well in terms of all the classification scores and has comparatively less difference with the precision and recall and I think the Logistic Regression model will be faster than the SVM models and it performs better and provides better results than the KNN model. So, my pick would be Logistic Regression model for this data analysis and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.75 \tAccuracy: 0.83\n",
      "\tPrecision: 0.8 \tRecall: 0.71\n",
      "2 . F1-score: 0.74 \tAccuracy: 0.82\n",
      "\tPrecision: 0.79 \tRecall: 0.7\n",
      "3 . F1-score: 0.74 \tAccuracy: 0.82\n",
      "\tPrecision: 0.79 \tRecall: 0.7\n",
      "4 . F1-score: 0.75 \tAccuracy: 0.83\n",
      "\tPrecision: 0.8 \tRecall: 0.71\n",
      "5 . F1-score: 0.75 \tAccuracy: 0.83\n",
      "\tPrecision: 0.79 \tRecall: 0.71\n",
      "Average f1-score: 0.75\n",
      "Average accuracy: 0.83\n",
      "Average precision: 0.79\n",
      "Average recall: 0.71\n"
     ]
    }
   ],
   "source": [
    "# With countries included\n",
    "wvs2 = wvs1.sample(n = 79000, random_state = 42).reset_index()\n",
    "wvs2 = wvs2.drop('index', axis = 1)\n",
    "\n",
    "X_final = wvs2.drop('abortion', axis = 1).to_numpy()\n",
    "y_final = wvs2['abortion']\n",
    "\n",
    "kfold_cross_val(5, logReg, X_final, y_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model predicts whether someone supports the abortion or not 83% of the time correctly and the classification scores are similar to the previous logistic regression model that we did with a sample dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . F1-score: 0.75 \tAccuracy: 0.83\n",
      "\tPrecision: 0.8 \tRecall: 0.7\n",
      "2 . F1-score: 0.74 \tAccuracy: 0.82\n",
      "\tPrecision: 0.79 \tRecall: 0.69\n",
      "3 . F1-score: 0.74 \tAccuracy: 0.82\n",
      "\tPrecision: 0.79 \tRecall: 0.69\n",
      "4 . F1-score: 0.75 \tAccuracy: 0.82\n",
      "\tPrecision: 0.79 \tRecall: 0.7\n",
      "5 . F1-score: 0.75 \tAccuracy: 0.83\n",
      "\tPrecision: 0.79 \tRecall: 0.71\n",
      "Average f1-score: 0.74\n",
      "Average accuracy: 0.82\n",
      "Average precision: 0.79\n",
      "Average recall: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Countries are excluded from the dataframe\n",
    "wvs2_no_country = wvs2.drop(list(wvs2.filter(regex = 'country')), axis = 1)\n",
    "\n",
    "X_final1 = wvs2_no_country.drop('abortion', axis = 1).to_numpy()\n",
    "y_final1 = wvs2_no_country['abortion']\n",
    "kfold_cross_val(5, logReg, X_final1, y_final1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't actually pose much difference between the regression models with and without the countries. Both the models still have the same accuracy and other classification scores.\n",
    "\n",
    "In this dataset, it shows that the nationality of people don't matter much in their opinion and the people's opinions are similar across the borders. So, in this dataset I believe that the country plays a very minimal role in rightly predicting whether a person supports abortion or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
